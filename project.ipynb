{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #to avoid some ugly warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(n, theta):\n",
    "    # input layer\n",
    "    input_layer = layers.Input(shape= (n,))\n",
    "    # drop out of 0.5 to the input\n",
    "    input_layer = tf.keras.layers.Dropout(0.5)(input_layer)\n",
    "    # dimensionality increasing\n",
    "    dimensionality = n+theta\n",
    "    # first encoding hidden layer H1\n",
    "    encoder_layer = layers.Dense(dimensionality, activation='tanh')(input_layer)\n",
    "    # dimensionality increasing\n",
    "    dimensionality = n+(2*theta)\n",
    "    # second encoding hidden layer H2\n",
    "    encoder_layer = layers.Dense(dimensionality, activation='tanh')(encoder_layer)\n",
    "    # dimensionality increasing\n",
    "    dimensionality = n+(3*theta)\n",
    "    # third encoding hidden layer H3\n",
    "    common_layer = layers.Dense(dimensionality, activation='tanh')(encoder_layer)\n",
    "    # dimensionality decreasing\n",
    "    dimensionality = n+(2*theta)\n",
    "    # second decoding hidden layer H4\n",
    "    decoder_layer = layers.Dense(dimensionality, activation='tanh')(common_layer)\n",
    "    # dimensionality decreasing\n",
    "    dimensionality = n+theta\n",
    "    # third decoding hidden layer H5\n",
    "    decoder_layer = layers.Dense(dimensionality, activation='tanh')(decoder_layer)\n",
    "    # output layer\n",
    "    output = layers.Dense(n, activation='tanh')(decoder_layer)\n",
    "   \n",
    "    return output_layer\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean_data(object):\n",
    "    def __init__(self):\n",
    "        self.bh_df = pd.read_csv('data/bh.csv', index_col=0)\n",
    "        self.bc_df = pd.read_csv('data/bc.csv', index_col=0)\n",
    "        self.dn_df = pd.read_csv('data/dna.csv', index_col=0)\n",
    "        self.gl_df = pd.read_csv('data/gl.csv', index_col=0)\n",
    "        self.hv_df = pd.read_csv('data/hv.csv', index_col=0)\n",
    "        self.is_df = pd.read_csv('data/is.csv', index_col=0)\n",
    "        self.on_df = pd.read_csv('data/on.csv', index_col=0)\n",
    "        self.sl_df = pd.read_csv('data/sl.csv', index_col=0)\n",
    "        self.sr_df = pd.read_csv('data/sr.csv', index_col=0)\n",
    "        self.st_df = pd.read_csv('data/st.csv', index_col=0)\n",
    "        self.sn_df = pd.read_csv('data/sn.csv', index_col=0)\n",
    "        self.sb_df = pd.read_csv('data/sb.csv', index_col=0)\n",
    "        self.vc_df = pd.read_csv('data/vc.csv', index_col=0)\n",
    "        self.vw_df = pd.read_csv('data/vw.csv', index_col=0)\n",
    "        self.zo_df = pd.read_csv('data/zo.csv', index_col=0)\n",
    "        \n",
    "    def BH_df(self):\n",
    "        '''\n",
    "        No modifications: it seems okay to be processed by the model.\n",
    "        '''\n",
    "        df = self.bh_df\n",
    "        return df\n",
    "    \n",
    "    def BC_df(self):\n",
    "        '''\n",
    "        Returns cleaned BC dataframe:\n",
    "        \n",
    "            - Class feature converted in 0 (malignant) and 1 (benign);\n",
    "            \n",
    "            - Id feature deleted (not useful information for the model).\n",
    "        '''\n",
    "        df = self.bc_df\n",
    "        # we have just 2 labels for class: one is opposite to the other\n",
    "        # so using binary values 0,1 is sufficient\n",
    "        df['Class'][df['Class']=='benign'] = 1\n",
    "        df['Class'][df['Class']=='malignant'] = 0\n",
    "        # drop id feature\n",
    "        df.drop(\"Id\", axis = 1, inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def DN_df(self):\n",
    "        '''\n",
    "        Returns cleaned DN dataframe:\n",
    "            - Class feature: one hot encoding is applied.\n",
    "        '''\n",
    "        df = self.dn_df\n",
    "        # we have more class labels: one hot encoding \n",
    "        df = pd.concat([df,pd.get_dummies(df.Class)], axis=1)\n",
    "        # drop class column\n",
    "        df.drop('Class', axis = 1, inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def GL_df(self):\n",
    "        '''\n",
    "        No modifications: it seems okay to be processed by the model.\n",
    "        '''\n",
    "        df = self.gl_df\n",
    "        return df\n",
    "    \n",
    "    def HV_df(self):\n",
    "        '''\n",
    "        Returns cleaned HV dataframe:\n",
    "            \n",
    "            - y values converted in 1 and n values converted in 0.\n",
    "            \n",
    "            - Class feature: one hot encoding is applied.\n",
    "        '''\n",
    "        df = self.hv_df\n",
    "        df = pd.concat([df,pd.get_dummies(df.Class)], axis=1)\n",
    "        # drop class column\n",
    "        df.drop('Class', axis = 1, inplace = True)\n",
    "        # substitution of y-n with 1-0\n",
    "        cols = df.columns\n",
    "        for feature in cols:\n",
    "            df[feature][df[feature]=='y'] = 1\n",
    "            df[feature][df[feature]=='n'] = 0\n",
    "        return df\n",
    "    \n",
    "    def IS_df(self):\n",
    "        '''\n",
    "        Returns cleaned IS dataframe:\n",
    "            \n",
    "            - Class feature converted in 0 (bad) and 1 (good).\n",
    "        '''\n",
    "        df = self.is_df\n",
    "        # substitution of bad-good with 0-1\n",
    "        df['Class'][df['Class']=='bad'] = 0\n",
    "        df['Class'][df['Class']=='good'] = 1\n",
    "        return df\n",
    "    \n",
    "    def ON_df(self):\n",
    "        '''\n",
    "        No modifications: it seems okay to be processed by the model.\n",
    "        '''       \n",
    "        df = self.on_df\n",
    "        return df\n",
    "    \n",
    "    def SL_df(self):\n",
    "        '''\n",
    "        Returns cleaned SL dataframe:\n",
    "            - classes: one hot encoding is applied.\n",
    "        '''\n",
    "        df = self.sl_df\n",
    "        # one hot encoding\n",
    "        df = pd.concat([df,pd.get_dummies(df.classes)], axis=1)\n",
    "        # drop classes column\n",
    "        df.drop('classes', axis = 1, inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def SR_df(self):\n",
    "        '''\n",
    "        Cleaned SR dataset with Motor and Screw classes converted to:\n",
    "            - 1 (A), \n",
    "            - 2 (B), \n",
    "            - 3 (C), \n",
    "            - 4 (D), \n",
    "            - 5 (E).\n",
    "        '''\n",
    "        df = self.sr_df\n",
    "        # converting in category numbers 1-5: labels are somehow ordered (A,B,..)\n",
    "        # so it's not necessary the one hot encoding\n",
    "        motor_labels = list(set(df.Motor))\n",
    "        screw_labels = list(set(df.Screw))\n",
    "        for i in range(len(motor_labels)):\n",
    "            df['Motor'][df['Motor'] == motor_labels[i]] = i+1\n",
    "            df['Screw'][df['Screw'] == screw_labels[i]] = i+1\n",
    "        return df\n",
    "    \n",
    "    def ST_df(self):\n",
    "        '''\n",
    "        Returns cleaned dataframe:\n",
    "            - Class feature: one hot encoding.\n",
    "        '''\n",
    "        df = self.st_df\n",
    "        # one hot encoding\n",
    "        df = pd.concat([df,pd.get_dummies(df.Class)], axis=1)\n",
    "        # drop class column\n",
    "        df.drop('Class', axis = 1, inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def SN_df(self):\n",
    "        '''\n",
    "        Returns cleaned SN dataframe:\n",
    "            - Class feature: one hot encoding.\n",
    "        '''\n",
    "        df = self.sn_df\n",
    "        # one hot encoding\n",
    "        df = pd.concat([df,pd.get_dummies(df.Class)], axis=1)\n",
    "        # drop class column\n",
    "        df.drop('Class', axis = 1, inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def SB_df(self):\n",
    "        '''\n",
    "        Returns cleaned SB dataframe:\n",
    "            - Class feature: one hot encoding is applied.\n",
    "        '''\n",
    "        \n",
    "        df = self.sb_df\n",
    "        # one hot encoding\n",
    "        df = pd.concat([df,pd.get_dummies(df.Class)], axis=1)\n",
    "        # drop class column\n",
    "        df.drop('Class', axis = 1, inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def VC_df(self):\n",
    "        '''\n",
    "        Returns cleaned VC dataframe:\n",
    "            - Class feature: one hot encoding is applied.\n",
    "        '''\n",
    "        df = self.vc_df\n",
    "        # one hot encoding\n",
    "        df = pd.concat([df,pd.get_dummies(df.Class)], axis=1)\n",
    "        # drop class column\n",
    "        df.drop(\"Class\", axis = 1, inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def VW_df(self):\n",
    "        '''\n",
    "        Returns cleaned VC dataframe:\n",
    "            - Class feature: one hot encoding is applied.\n",
    "        '''\n",
    "        \n",
    "        df = self.vw_df\n",
    "        # one hot encoding\n",
    "        df = pd.concat([df,pd.get_dummies(df.Class)], axis=1)\n",
    "        # drop class column\n",
    "        df.drop(\"Class\", axis = 1, inplace = True)\n",
    "        return df\n",
    "    \n",
    "    def ZO_df(self):\n",
    "        '''\n",
    "        Returns cleaned VC dataframe: \n",
    "            - features having boolean values: substitution with 1 (True) and 0 (False).\n",
    "            - type feature: one hot encoding.\n",
    "        '''\n",
    "        df = self.zo_df\n",
    "        # substitution of true-false with 1-0\n",
    "        col_names = df.columns\n",
    "        for feat in col_names:\n",
    "            try:\n",
    "                df[feat][df[feat] == True] = 1\n",
    "                df[feat][df[feat] == False] = 0\n",
    "            except:\n",
    "                pass\n",
    "        # one hot encoding\n",
    "        df = pd.concat([df,pd.get_dummies(df.type)], axis=1)\n",
    "        # drop type column\n",
    "        df.drop(\"type\", axis = 1, inplace = True)\n",
    "        return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = clean_data()\n",
    "bh_df = cleaner.BH_df()\n",
    "bc_df = cleaner.BC_df()\n",
    "dn_df = cleaner.DN_df()\n",
    "gl_df = cleaner.GL_df()\n",
    "hv_df = cleaner.HV_df()\n",
    "is_df = cleaner.IS_df()\n",
    "on_df = cleaner.ON_df()\n",
    "sl_df = cleaner.SL_df()\n",
    "sr_df = cleaner.SR_df()\n",
    "st_df = cleaner.ST_df()\n",
    "sn_df = cleaner.SN_df()\n",
    "sb_df = cleaner.SB_df()\n",
    "vc_df = cleaner.VC_df()\n",
    "vw_df = cleaner.VW_df()\n",
    "zo_df = cleaner.ZO_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class missingness(object):\n",
    "    \n",
    "    def __init__(self, file, th):\n",
    "        # load dataset\n",
    "        self.df = pd.read_csv(file, index_col=0)\n",
    "        # set missingness proportion\n",
    "        self.th = th\n",
    "        # random uniform vector with values in [0,1], length = n obs.\n",
    "        self.vector_1 = np.random.uniform(0,1,len(self.df))\n",
    "        # number of features\n",
    "        self.n_attributes = len(self.df.columns)\n",
    "        # list of feature indeces\n",
    "        self.attr_idx = [i for i in range(self.n_attributes)]\n",
    "        \n",
    "    def MCAR_uniform(self):\n",
    "        df_mcar_uni = self.df\n",
    "        ### MCAR uniform \n",
    "        # initialize col with random uniform vector\n",
    "        df_mcar_uni['MCAR uniform'] = self.vector_1\n",
    "        # set values of feature under threshold to nan\n",
    "        df_mcar_uni[df_mcar_uni['MCAR uniform'] <= self.th] = np.nan\n",
    "        return df_mcar_uni\n",
    "    \n",
    "    def MCAR_random(self):\n",
    "        df_mcar_rand = self.df\n",
    "        ### MCAR random\n",
    "        # initialize col with random uniform vector\n",
    "        df_mcar_rand['MCAR random'] = self.vector_1\n",
    "        # random half sample of feature indeces\n",
    "        half_attr = np.random.choice(self.attr_idx, size =self.n_attributes//2,replace= False)\n",
    "        # set values of selected features to nan in correspondence of values under th\n",
    "        df_mcar_rand.iloc[:, half_attr][df_mcar_rand['MCAR random']<=th] = np.nan\n",
    "        return df_mcar_rand\n",
    "     \n",
    "    def MNAR_uniform(self):\n",
    "        df_mnar_uni = self.df\n",
    "        ### MNAR uniform \n",
    "        # initialize col with random uniform vector\n",
    "        df_mnar_uni['MNAR uniform'] = self.vector_1\n",
    "        # pick 2 random attributes\n",
    "        attr_2_idx = np.random.choice(self.attr_idx, size = 2, replace=False)\n",
    "        median_1 = df_mnar_uni.iloc[:,attr_2_idx[0]].median(skipna = False)\n",
    "        median_2 = df_mnar_uni.iloc[:, attr_2_idx[1]].median(skipna = False)\n",
    "        # ???\n",
    "        df_mnar_uni[(df_mnar_uni['MNAR uniform']<= th & (df_mnar_uni.iloc[:,attr_2_idx[0]] <= median_1 | df_mnar_uni.iloc[:,attr_2_idx[1]] >= median_2))] = np.nan\n",
    "        return df_mnar_uni\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
