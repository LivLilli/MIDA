{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(n, theta):\n",
    "    # input layer\n",
    "    input_layer = layers.Input(shape= (n,))\n",
    "    # dimensionality increasing\n",
    "    dimensionality = n+theta\n",
    "    # first encoding hidden layer H1\n",
    "    encoder_layer = layers.Dense(dimensionality, activation='tanh')(input_layer)\n",
    "    # dimensionality increasing\n",
    "    dimensionality = n+(2*theta)\n",
    "    # second encoding hidden layer H2\n",
    "    encoder_layer = layers.Dense(dimensionality, activation='tanh')(encoder_layer)\n",
    "    # dimensionality increasing\n",
    "    dimensionality = n+(3*theta)\n",
    "    # third encoding hidden layer H3\n",
    "    encoder_layer = layers.Dense(dimensionality, activation='tanh')(encoder_layer)\n",
    "    # first decoding hidden layer H3\n",
    "    decoder_layer = layers.Dense(dimensionality, activation='tanh')(encoder_layer)\n",
    "    # dimensionality decreasing\n",
    "    dimensionality = n+(2*theta)\n",
    "    # second decoding hidden layer H4\n",
    "    decoder_layer = layers.Dense(dimensionality, activation='tanh')(decoder_layer)\n",
    "    # dimensionality decreasing\n",
    "    dimensionality = n+theta\n",
    "    # third decoding hidden layer H5\n",
    "    decoder_layer = layers.Dense(dimensionality, activation='tanh')(decoder_layer)\n",
    "    # output layer\n",
    "    output = layers.Dense(n, activation='tanh')(decoder_layer)\n",
    "   \n",
    "    return output_layer\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class missingness(object):\n",
    "    \n",
    "    def __init__(self, file, th):\n",
    "        # load dataset\n",
    "        self.df = pd.read_csv(file, index_col=0)\n",
    "        # set missingness proportion\n",
    "        self.th = th\n",
    "        # random uniform vector with values in [0,1], length = n obs.\n",
    "        self.vector_1 = np.random.uniform(0,1,len(self.df))\n",
    "        \n",
    "    def MCAR_uniform(self):\n",
    "        df_mcar_uni = self.df\n",
    "        ### MCAR uniform vector\n",
    "        df_mcar_uni['MCAR uniform'] = self.vector_1\n",
    "        # set values of feature under threshold to nan\n",
    "        df_mcar_uni[df_mcar_uni['MCAR uniform'] <= self.th] = np.nan\n",
    "        return df_mcar_uni\n",
    "    \n",
    "    def MCAR_random(self):\n",
    "        df_mcar_rand = self.df\n",
    "        ### MCAR random\n",
    "        # initialize col with random uniform vector\n",
    "        df_mcar_rand['MCAR random'] = self.vector_1\n",
    "        # number of features\n",
    "        n_attributes = len(self.df.columns)\n",
    "        # list of feature indeces\n",
    "        attr_idx = [i for i in range(n_attributes)]\n",
    "        # random half sample of feature indeces\n",
    "        half_attr = np.random.choice(attr_idx, size =n_attributes//2,replace= False)\n",
    "        # set values of selected features to nan in correspondence of values under th\n",
    "        df_mcar_rand.iloc[:, half_attr][df_mcar_rand['MCAR random']<=th] = np.nan\n",
    "        return df_mcar_rand\n",
    "    \n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
