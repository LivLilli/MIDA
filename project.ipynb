{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') #to avoid some ugly warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(n, theta):\n",
    "    # input layer\n",
    "    input_layer = layers.Input(shape= (n,))\n",
    "    # dimensionality increasing\n",
    "    dimensionality = n+theta\n",
    "    # first encoding hidden layer H1\n",
    "    encoder_layer = layers.Dense(dimensionality, activation='tanh')(input_layer)\n",
    "    # dimensionality increasing\n",
    "    dimensionality = n+(2*theta)\n",
    "    # second encoding hidden layer H2\n",
    "    encoder_layer = layers.Dense(dimensionality, activation='tanh')(encoder_layer)\n",
    "    # dimensionality increasing\n",
    "    dimensionality = n+(3*theta)\n",
    "    # third encoding hidden layer H3\n",
    "    encoder_layer = layers.Dense(dimensionality, activation='tanh')(encoder_layer)\n",
    "    # first decoding hidden layer H3\n",
    "    decoder_layer = layers.Dense(dimensionality, activation='tanh')(encoder_layer)\n",
    "    # dimensionality decreasing\n",
    "    dimensionality = n+(2*theta)\n",
    "    # second decoding hidden layer H4\n",
    "    decoder_layer = layers.Dense(dimensionality, activation='tanh')(decoder_layer)\n",
    "    # dimensionality decreasing\n",
    "    dimensionality = n+theta\n",
    "    # third decoding hidden layer H5\n",
    "    decoder_layer = layers.Dense(dimensionality, activation='tanh')(decoder_layer)\n",
    "    # output layer\n",
    "    output = layers.Dense(n, activation='tanh')(decoder_layer)\n",
    "   \n",
    "    return output_layer\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clean_data(object):\n",
    "    def __init__(self):\n",
    "        self.bh_df = pd.read_csv('data/bh.csv', index_col=0)\n",
    "        self.bc_df = pd.read_csv('data/bc.csv', index_col=0)\n",
    "        self.dn_df = pd.read_csv('data/dna.csv', index_col=0)\n",
    "        self.gl_df = pd.read_csv('data/gl.csv', index_col=0)\n",
    "        self.hv_df = pd.read_csv('data/hv.csv', index_col=0)\n",
    "        self.is_df = pd.read_csv('data/is.csv', index_col=0)\n",
    "        self.on_df = pd.read_csv('data/on.csv', index_col=0)\n",
    "        self.sl_df = pd.read_csv('data/sl.csv', index_col=0)\n",
    "        self.sr_df = pd.read_csv('data/sr.csv', index_col=0)\n",
    "        self.st_df = pd.read_csv('data/st.csv', index_col=0)\n",
    "        self.sn_df = pd.read_csv('data/sn.csv', index_col=0)\n",
    "        self.sb_df = pd.read_csv('data/sb.csv', index_col=0)\n",
    "        self.vc_df = pd.read_csv('data/vc.csv', index_col=0)\n",
    "        \n",
    "    def BH_df(self):\n",
    "        '''\n",
    "        No modifications: it seems okay to be processed by the model.\n",
    "        '''\n",
    "        df = self.bh_df\n",
    "        return df\n",
    "    \n",
    "    def BC_df(self):\n",
    "        '''\n",
    "        Returns cleaned BC dataframe:\n",
    "        \n",
    "            - Class feature converted in 0 (malignant) and 1 (benign);\n",
    "            \n",
    "            - Id feature deleted (not useful information for the model).\n",
    "        '''\n",
    "        df = self.bc_df\n",
    "        df['Class'][df['Class']=='benign'] = 1\n",
    "        df['Class'][df['Class']=='malignant'] = 0\n",
    "        df.drop(\"Id\", axis = 1, inplace = True)\n",
    "        return df\n",
    "    def DN_df(self):\n",
    "        '''\n",
    "        Returns cleaned DN dataframe:\n",
    "            - Class feature converted in 1 (ei), 2 (ie) and 3 (n)\n",
    "        '''\n",
    "        df = self.dn_df\n",
    "        df['Class'][df['Class']=='ei'] = 1\n",
    "        df['Class'][df['Class']=='ie'] = 2\n",
    "        df['Class'][df['Class']=='n'] = 3\n",
    "        return df\n",
    "    def GL_df(self):\n",
    "        '''\n",
    "        No modifications: it seems okay to be processed by the model.\n",
    "        '''\n",
    "        df = self.gl_df\n",
    "        return df\n",
    "    def HV_df(self):\n",
    "        '''\n",
    "        Returns cleaned HV dataframe:\n",
    "            \n",
    "            - y values converted in 1 and n values converted in 0.\n",
    "            \n",
    "            - Class feature converted in 1 (democrat) and 2 (republican).\n",
    "        '''\n",
    "        df = self.hv_df\n",
    "        df['Class'][df['Class']=='democrat'] = 1\n",
    "        df['Class'][df['Class']=='republican'] = 2\n",
    "        cols = df.columns\n",
    "        for feature in cols:\n",
    "            df[feature][df[feature]=='y'] = 1\n",
    "            df[feature][df[feature]=='n'] = 0\n",
    "        return df\n",
    "    def IS_df(self):\n",
    "        '''\n",
    "        Returns cleaned IS dataframe:\n",
    "            \n",
    "            - Class feature converted in 0 (bad) and 1 (good).\n",
    "        '''\n",
    "        df = self.is_df\n",
    "        df['Class'][df['Class']=='bad'] = 0\n",
    "        df['Class'][df['Class']=='good'] = 1\n",
    "        return df\n",
    "    def ON_df(self):\n",
    "        '''\n",
    "        No modifications: it seems okay to be processed by the model.\n",
    "        '''       \n",
    "        df = self.on_df\n",
    "        return df\n",
    "    def SL_df(self):\n",
    "        '''\n",
    "        Returns cleaned SL dataframe with classes:\n",
    "        \n",
    "            - 1 for damp grey soil;\n",
    "            \n",
    "            - 2 for red soil;\n",
    "            \n",
    "            - 3 for grey soil;\n",
    "            \n",
    "            - 4 for vegetation stubble;\n",
    "            \n",
    "            - 5 for very damp grey soil;\n",
    "            \n",
    "            - 6 for cotton crop.\n",
    "        '''\n",
    "        df = self.sl_df\n",
    "        \n",
    "        classes_values = list(set(df.classes))\n",
    "        for i in range(0, len(classes_values)):\n",
    "            df['classes'][df['classes']== classes_values[i]] = i+1\n",
    "        \n",
    "        return df\n",
    "    def SR_df(self):\n",
    "        '''\n",
    "        Cleaned SR dataset with Motor and Screw classes converted to:\n",
    "            - 1 (A), \n",
    "            - 2 (B), \n",
    "            - 3 (C), \n",
    "            - 4 (D), \n",
    "            - 5 (E).\n",
    "        '''\n",
    "        df = self.sr_df\n",
    "        motor_labels = list(set(df.Motor))\n",
    "        screw_labels = list(set(df.Screw))\n",
    "        for i in range(len(motor_labels)):\n",
    "            df['Motor'][df['Motor'] == motor_labels[i]] = i+1\n",
    "            df['Screw'][df['Screw'] == screw_labels[i]] = i+1\n",
    "    def ST_df(self):\n",
    "        '''\n",
    "        Returns cleaned dataframe with Class feature converted to:\n",
    "        \n",
    "            - 1 (Bpv.Close);\n",
    "            \n",
    "            - 2 (Bpv.Open);\n",
    "            \n",
    "            - 3 (Bypass);\n",
    "            \n",
    "            - 4 (Fpv.Close);\n",
    "            \n",
    "            - 5 (High);\n",
    "            \n",
    "            - 6 (Rad.Flow).\n",
    "        '''\n",
    "        df = self.st_df\n",
    "        class_labels = list(set(df.Class))\n",
    "        for i in range(len(class_labels)):\n",
    "            df['Class'][df['Class'] == class_labels[i]] = i+1\n",
    "        return df\n",
    "    def SN_df(self):\n",
    "        '''\n",
    "        Returns cleaned SN dataframe with Class feature converted to:\n",
    "        \n",
    "            - 1 (M);\n",
    "            \n",
    "            - 2 (R).\n",
    "        '''\n",
    "        df = self.sn_df\n",
    "        df['Class'][df['Class'] == 'M'] = 1\n",
    "        df['Class'][df['Class'] == 'R'] = 2\n",
    "        \n",
    "        return df\n",
    "    def SB_df(self):\n",
    "        '''\n",
    "        Returns cleaned SB dataframe with Class feature converted to numbers from 1 to 19 \n",
    "            for the 19 different class labels\n",
    "        '''\n",
    "        \n",
    "        df = self.sb_df\n",
    "    \n",
    "        class_labels = list(set(sb_df['Class']))\n",
    "        for i in range(len(class_labels)):\n",
    "            df['Class'][df['Class'] == class_labels[i]] = i+1\n",
    "\n",
    "        return df\n",
    "    def VC_df(self):\n",
    "        '''\n",
    "        '''\n",
    "        df = self.vc_df\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = clean_data()\n",
    "bh_df = cleaner.BH_df()\n",
    "bc_df = cleaner.BC_df()\n",
    "dn_df = cleaner.DN_df()\n",
    "gl_df = cleaner.GL_df()\n",
    "hv_df = cleaner.HV_df()\n",
    "is_df = cleaner.IS_df()\n",
    "on_df = cleaner.ON_df()\n",
    "sl_df = cleaner.SL_df()\n",
    "sr_df = cleaner.SR_df()\n",
    "st_df = cleaner.ST_df()\n",
    "sn_df = cleaner.SN_df()\n",
    "sb_df = cleaner.SB_df()\n",
    "vc_df = cleaner.VC_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bus', 'opel', 'saab', 'van'}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(vc_df.Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class missingness(object):\n",
    "    \n",
    "    def __init__(self, file, th):\n",
    "        # load dataset\n",
    "        self.df = pd.read_csv(file, index_col=0)\n",
    "        # set missingness proportion\n",
    "        self.th = th\n",
    "        # random uniform vector with values in [0,1], length = n obs.\n",
    "        self.vector_1 = np.random.uniform(0,1,len(self.df))\n",
    "        # number of features\n",
    "        self.n_attributes = len(self.df.columns)\n",
    "        # list of feature indeces\n",
    "        self.attr_idx = [i for i in range(self.n_attributes)]\n",
    "        \n",
    "    def MCAR_uniform(self):\n",
    "        df_mcar_uni = self.df\n",
    "        ### MCAR uniform \n",
    "        # initialize col with random uniform vector\n",
    "        df_mcar_uni['MCAR uniform'] = self.vector_1\n",
    "        # set values of feature under threshold to nan\n",
    "        df_mcar_uni[df_mcar_uni['MCAR uniform'] <= self.th] = np.nan\n",
    "        return df_mcar_uni\n",
    "    \n",
    "    def MCAR_random(self):\n",
    "        df_mcar_rand = self.df\n",
    "        ### MCAR random\n",
    "        # initialize col with random uniform vector\n",
    "        df_mcar_rand['MCAR random'] = self.vector_1\n",
    "        # random half sample of feature indeces\n",
    "        half_attr = np.random.choice(self.attr_idx, size =self.n_attributes//2,replace= False)\n",
    "        # set values of selected features to nan in correspondence of values under th\n",
    "        df_mcar_rand.iloc[:, half_attr][df_mcar_rand['MCAR random']<=th] = np.nan\n",
    "        return df_mcar_rand\n",
    "     \n",
    "    def MNAR_uniform(self):\n",
    "        df_mnar_uni = self.df\n",
    "        ### MNAR uniform \n",
    "        # initialize col with random uniform vector\n",
    "        df_mnar_uni['MNAR uniform'] = self.vector_1\n",
    "        # pick 2 random attributes\n",
    "        attr_2_idx = np.random.choice(self.attr_idx, size = 2, replace=False)\n",
    "        median_1 = df_mnar_uni.iloc[:,attr_2_idx[0]].median(skipna = False)\n",
    "        median_2 = df_mnar_uni.iloc[:, attr_2_idx[1]].median(skipna = False)\n",
    "        # ???\n",
    "        df_mnar_uni[(df_mnar_uni['MNAR uniform']<= th & (df_mnar_uni.iloc[:,attr_2_idx[0]] <= median_1 | df_mnar_uni.iloc[:,attr_2_idx[1]] >= median_2))] = np.nan\n",
    "        return df_mnar_uni\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
